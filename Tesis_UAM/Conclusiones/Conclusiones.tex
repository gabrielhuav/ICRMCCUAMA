%!TEX root = ../ICR.tex
\chapter{Conclusiones}
\label{cap:Conclusiones}

El presente trabajo de investigación se propuso desarrollar y validar un método computacional para la detección de noticias falsas en español, un área de creciente relevancia social pero con una notable escasez de recursos especializados. A través de una metodología evolutiva, se exploraron dos paradigmas de la inteligencia artificial, desde enfoques clásicos optimizados hasta modelos de lenguaje de última generación, cumpliendo así el \textbf{objetivo general} de desarrollar un método de detección con una metodología transferible a otros tipos de fraude digital.

La consecución de este objetivo fue posible gracias al cumplimiento de metas específicas que guiaron cada etapa del proyecto:

En primer lugar, se logró \textbf{recopilar y procesar un conjunto de datos diverso y a gran escala}, unificando cuatro corpus académicos y enriqueciéndolo con más de 9,000 noticias obtenidas mediante técnicas de \textit{extracción web}. El resultado es un corpus balanceado de más de 61,000 registros, que se constituye como una de las contribuciones fundamentales de este trabajo al proveer un recurso robusto para la comunidad de investigación en español.

Posteriormente, se \textbf{implementó un sistema de detección inicial} que combinó la representación textual TF-IDF con la optimización de cinco algoritmos metaheurísticos. Este enfoque no solo estableció una sólida línea base de rendimiento, sino que también permitió una caracterización detallada del comportamiento de cada algoritmo, cuyos hallazgos fueron validados a través de una publicación científica.

Para superar las limitaciones inherentes a los modelos clásicos, se \textbf{desarrolló un sistema de detección avanzado mediante el ajuste fino (\textit{fine-tuning}) de un modelo de lenguaje profundo (\texttt{DistilBERT})}. A través de una rigurosa calibración de hiperparámetros y la aplicación de técnicas avanzadas para mitigar el sobreajuste, se logró optimizar su rendimiento de manera significativa, alcanzando una notable precisión en la clasificación de textos.

El \textbf{análisis comparativo} entre ambos enfoques arrojó resultados concluyentes. El modelo DistilBERT demostró una superioridad categórica, con una exactitud final del 95.2\%, superando por más de 24 puntos porcentuales al mejor modelo metaheurístico. Este hallazgo valida empíricamente la eficacia de las arquitecturas de aprendizaje profundo para comprender los matices semánticos y contextuales del lenguaje en la detección de desinformación.

Finalmente, para demostrar la aplicabilidad práctica de la investigación, se \textbf{desarrolló un prototipo de aplicación web funcional}, contenerizada con \texttt{Docker}. Esta herramienta integra el modelo Transformer de mayor rendimiento y permite el análisis de URLs en tiempo real, validando su potencial no solo para la detección de noticias falsas, sino como una base sólida y extensible para combatir diversas formas de fraude digital.

En síntesis, esta investigación ha cumplido exitosamente con sus objetivos, entregando un corpus a gran escala, una comparativa metodológica rigurosa y, fundamentalmente, un modelo de alto rendimiento materializado en una herramienta práctica. Con ello, se sientan bases sólidas para futuras innovaciones en la lucha contra la desinformación en el ecosistema digital de habla hispana.